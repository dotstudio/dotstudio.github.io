<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>handson on dotstudio（ドットスタジオ）</title><link>https://dotstud.io/categories/handson/</link><description>Recent content in handson on dotstudio（ドットスタジオ）</description><generator>Hugo -- gohugo.io</generator><language>ja</language><copyright>© 2018 dotstudio inc.</copyright><lastBuildDate>Thu, 13 Dec 2018 05:17:31 +0900</lastBuildDate><atom:link href="/categories/handson/" rel="self" type="application/rss+xml"/><item><title>【ハンズオン資料】GR-LYCHEEとOpenCVで画像認識やってみよう</title><link>https://dotstud.io/blog/gr-lychee-opencv-handson/</link><pubDate>Thu, 13 Dec 2018 05:17:31 +0900</pubDate><guid>https://dotstud.io/blog/gr-lychee-opencv-handson/</guid><description>&lt;p>この記事は12/07の&lt;a href="https://ai-iot-bol-fukui.connpass.com/event/109573/">AI×IoT ハンズオン with IoTLT&amp;amp;ふくもく会 in 福井&lt;/a>向け資料です。記事を読んで試せる内容になっているので、終了後や参加されていない方もぜひ試してみてください！&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>この記事はがじぇっとるねさすさんの「&lt;a href="http://gadget.renesas.com/ja/product/e-ai/mnist_tutorial.html">e-AIトランスレータ チュートリアル GRボードで実行してみよう！&lt;/a>」を参考に作成しています。&lt;/p>
&lt;h2 id="heading">今回やってみること&lt;/h2>
&lt;p>PythonとTensorflow、数字認識のデータライブラリMNISTを使い、数字認識する学習モデルを作成します。&lt;strong>Pythonなしでもコピペで試せる内容&lt;/strong>になっています。&lt;/p>
&lt;p>&lt;img src="https://dotstud.io/img/blog/233/result.gif" alt="demo">&lt;/p>
&lt;h3 id="heading-1">用意するもの&lt;/h3>
&lt;h4 id="gr-lychee">■マイコンボード「GR-LYCHEE」&lt;/h4>
&lt;p>&lt;img src="https://i.gyazo.com/714caa81da618bf491f460087f27d3cb.jpg" alt="">&lt;/p>
&lt;p>がじぇっとるねさす（通称がじぇるね）が提供している高性能マイコンボードです。電子工作でよく使われるArduino UNOとピンが互換になっていて、Wi-Fi・BLE通信モジュール「ESP32」を搭載しています。&lt;/p>
&lt;p>わりと手軽にIoTプロトタイピングを試せる高性能マイコンボード、な立ち位置です。（ちゃんとく所感）&lt;/p>
&lt;ul>
&lt;li>購入: &lt;a href="http://akizukidenshi.com/catalog/g/gM-12850/">秋月電子&lt;/a>（¥10,580）&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="usbmicrob">■USBケーブル（microB）&lt;/h4>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>PCとGR-LYCHEEの通信（プログラムの書き込み、カメラ映像の出力など）には、Android端末などに使われているmicroBタイプのUSBケーブルを使います。&lt;/p>
&lt;ul>
&lt;li>購入: &lt;a href="http://akizukidenshi.com/catalog/g/gC-09312/">秋月電子&lt;/a>（¥100）&lt;/li>
&lt;/ul>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h2 id="heading-2">事前準備&lt;/h2>
&lt;h3 id="displayapp">「DisplayApp」をインストール&lt;/h3>
&lt;p>GR-LYCHEEのカメラで映している映像を確認するために利用します。&lt;/p>
&lt;p>&lt;a href="http://gadget.renesas.com/ja/product/lychee.html#displayapp">&lt;img src="https://i.gyazo.com/5cf7140ebfb5221592c1ca7f6aa7f839.png" alt="Image from Gyazo">&lt;/a>&lt;/p>
&lt;p>がじぇるね公式ページの&lt;a href="http://gadget.renesas.com/ja/product/lychee.html#displayapp">こちら&lt;/a>からご自身のOSに合ったものをダウンロードし、ZIPファイルを展開します。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="macos">■MacOSの方&lt;/h4>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>ZIPファイルを展開し、Macの方は「アプリケーション」に移動させます。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="windows">■Windowsの方&lt;/h4>
&lt;p>展開したファイル内の「〜.exe」をダブルクリックで実行します。インストーラが起動するので、手順通り進めます。&lt;/p>
&lt;h2 id="heading-3">はじめてのプログラムを書き込んでみる&lt;/h2>
&lt;p>最初のプログラムとして、Lチカをやってみます。LEDチカチカの略で、入門向けのプログラムとして汎用的に紹介されています。&lt;/p>
&lt;p>簡単なプログラムを書き込むことで、ボードが正常に動くか試す際に利用することも多いです。WebでいうHello, worldです。&lt;/p>
&lt;h3 id="web">Webコンパイラの準備&lt;/h3>
&lt;p>GRシリーズでは「Webコンパイラ」という、ブラウザ上で利用できるコンパイラが利用できます。面倒な環境構築が不要なので楽チンですね。&lt;/p>
&lt;p>&lt;a href="http://gadget.renesas.com/ja/">がじぇるねのページ&lt;/a>から、「ログイン」または「ゲストログイン」をクリックし移動します。
&lt;img src="https://i.gyazo.com/bcf47b506593c244633350381c30422f.png" alt="compiler">&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>プロジェクト作成画面になるので、「LYCHEE」でフィルターをかけてみます。
&lt;img src="https://i.gyazo.com/9fbdd84ff53037965a358bc646d3923c.png" alt="create project">
「GR-LYCHEE_mbed…」と「GR-LYCHEE_Sketch…」という2タイプあるので、&lt;strong>Sketchの方を選択&lt;/strong>します（mbed OSのプログラムを利用したいときは前者を選びましょう）。&lt;/p>
&lt;h3 id="heading-4">プログラム&lt;/h3>
&lt;p>メニュー左側の「〜.cpp」という拡張子のファイルがメインのプログラムファイルになります。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>「〜.cpp」をダブルクリックすると、中央に編集画面が表示されます。&lt;/p>
&lt;p>表示されたサンプルコードを&lt;strong>一旦全て消してから&lt;/strong>、下記のプログラムを貼り付けます。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code> #define INTERVAL 50
void setup()
{
Serial.begin(9600);
pinMode(LED_RED, OUTPUT);
pinMode(LED_ORANGE, OUTPUT);
pinMode(LED_YELLOW, OUTPUT);
pinMode(LED_GREEN, OUTPUT);
pinMode(USER_BUTTON0, INPUT);
}
void loop()
{
while(digitalRead(USER_BUTTON0) == 0){
digitalWrite(LED_GREEN, 1);
delay(INTERVAL);
digitalWrite(LED_GREEN, 0);
delay(INTERVAL);
Serial.println(&amp;quot;I'm LYCHEE!&amp;quot;);
}
digitalWrite(LED_RED, 1);
delay(INTERVAL);
digitalWrite(LED_RED, 0);
digitalWrite(LED_ORANGE, 1);
delay(INTERVAL);
digitalWrite(LED_ORANGE, 0);
digitalWrite(LED_YELLOW, 1);
delay(INTERVAL);
digitalWrite(LED_YELLOW, 0);
}
&amp;lt;/code&amp;gt;
&amp;lt;/pre&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>貼り付けたら、右側の「ビルド実行」ボタンをクリックし、記述したプログラムをコンパイルします。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>コンパイルが完了すると、「コンパイルが完了しました」というメッセージと実行ログが表示されるので、「&lt;strong>閉じる&lt;/strong>」ボタンで完了します。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>「〜.bin」というファイルが作成されているので、右クリックしダウンロードします。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h3 id="pcgr-lychee">PCとGR-LYCHEEを接続&lt;/h3>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>GR-LYCHEEとPCをUSBケーブルで接続しましょう。GR-LYCHEEのUSBソケットは&lt;strong>真ん中の方&lt;/strong>です。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>PCに「MBED」という名前で認識されます。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="windows-1">■デバイスが認識されない（Windows）&lt;/h4>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>&lt;a href="https://os.mbed.com/docs/latest/tutorials/windows-serial-driver.html">こちら&lt;/a>のページから「Arm Mbed Windows serial port driver」をクリックし、インストールしてください。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h3 id="heading-5">プログラムを書き込み&lt;/h3>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>ダウンロードした「〜.bin」ファイルを「MBED」にドラッグ＆ドロップでコピーします。コピー後、ファイルはMBEDフォルダ内には表示されません。&lt;/p>
&lt;h3 id="heading-6">再起動して実行&lt;/h3>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>リセットボタンを押し、GR-LYCHEEを再起動させます。&lt;/p>
&lt;p>&lt;img src="https://dotstud.io/img/blog/233/blink.gif" alt="blink">&lt;/p>
&lt;p>Lチカプログラムが実行されました！&lt;/p>
&lt;h2 id="gr-lycheedisplayapp">GR-LYCHEEカメラの映像をdisplayAppに表示&lt;/h2>
&lt;p>&lt;img src="https://dotstud.io/img/blog/233/display.gif" alt="display">&lt;/p>
&lt;p>GR-LYCHEEにカメラを取り付けて、PC上で映る映像を確認してみましょう。&lt;/p>
&lt;h3 id="heading-7">カメラの取り付け&lt;/h3>
&lt;h4 id="heading-8">■カメラ本体&lt;/h4>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;ol>
&lt;li>カメラ本体のソケット部を持ち上げます&lt;/li>
&lt;li>フレキシブルケーブルの無地面を上に、ソケットに差し込みます&lt;/li>
&lt;li>ソケット部を元に戻します&lt;/li>
&lt;/ol>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="gr-lychee-1">■GR-LYCHEE&lt;/h4>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;ol>
&lt;li>GR-LYCHEE背面のソケット部を上にずらします&lt;/li>
&lt;li>フレキシブルケーブルの文字面を上に、ソケットに差し込みます&lt;/li>
&lt;li>ソケット部を下に戻します&lt;/li>
&lt;/ol>
&lt;h3 id="heading-9">プログラム&lt;/h3>
&lt;p>Webコンパイラでプログラムを下記に置き換え、先ほど同様書き込みます。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code> #include &amp;amp;lt;Arduino.h&amp;amp;gt;
#include &amp;amp;lt;Camera.h&amp;amp;gt;
#include &amp;quot;DisplayApp.h&amp;quot;
#define LOOP_WAITTIME 17 // 17ms for 60 fps of camera spec.
Camera camera(640, 480);
static DisplayApp display_app;
void setup() {
Serial.begin(9600);
Serial.println(&amp;quot;start&amp;quot;);
camera.begin();
}
void loop() {
static unsigned long last_time = millis();
while ((millis() - last_time) &amp;lt; LOOP_WAITTIME);
last_time = millis();
display_app.SendJpeg(camera.getJpegAdr(), (int)camera.createJpeg());
delay(1);
}
&amp;lt;/code&amp;gt;
&amp;lt;/pre&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;h3 id="usb">USBを付け替えて実行&lt;/h3>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>書き込んだら、GR-LYCHEE側のUSBソケットを外側に付け替えます。（通信用）&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>DisplayAppでシリアルポートを選択します。&lt;/p>
&lt;p>&lt;img src="https://dotstud.io/img/blog/233/display.gif" alt="display">
カメラの画像がDisplayAppに表示されます。高画質！&lt;/p>
&lt;h2 id="heading-10">数字認識の学習モデルを作ろう&lt;/h2>
&lt;p>MNISTとTensorflowを使って学習モデルを作り、カメラに映った数字を判定するプログラムを作成してみます。&lt;/p>
&lt;p>&lt;strong>Python+Tensorflowをインストールせず試してみたい&lt;/strong>、という方は、「&lt;a href="#%E5%AE%8C%E6%88%90%E3%82%B3%E3%83%BC%E3%83%89">完成コード&lt;/a>」の章から進めてください。&lt;/p>
&lt;h3 id="heading-11">作業用ディレクトリを作成&lt;/h3>
&lt;p>今回のプログラムを試すディレクトリ（フォルダ）を作ります。&lt;/p>
&lt;p>プログラムを実行する上では&lt;strong>今どこで作業しているか&lt;/strong>というのが重要です。最初のうちはわかりづらいので、意識するようにしましょう。&lt;/p>
&lt;p>コマンドラインに不慣れである方は、下記記事を参照してみてください。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="windows-2">■Windowsの方&lt;/h4>
&lt;ol>
&lt;li>デスクトップで右クリックし、&lt;code>gr-tutorial&lt;/code>というファイルを作成&lt;/li>
&lt;li>Windowsメニューから「コマンドラインプロンプト」を検索し開く（「cmd」で候補にでてきます）&lt;/li>
&lt;li>下記コマンドを1行ずつ実行（&lt;code>$&lt;/code>は不要。コマンドラインであることを表しています）&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>$ cd Desktop
$ cd gr-tutorial
&lt;/code>&lt;/pre>&lt;p>&lt;code>cd&lt;/code>はディレクトリを移動するコマンドです。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="mac">■Macの方&lt;/h4>
&lt;ol>
&lt;li>「ターミナル」を起動（⌘+スペースで「ターミナル」を検索すると便利）&lt;/li>
&lt;li>下記コマンドを1行ずつ順に打ち込む（&lt;code>$&lt;/code>は不要。コマンドラインであることを表しています）&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>$ cd ~/Desktop
$ mkdir gr-tutorial
$ cd gr-tutorial
&lt;/code>&lt;/pre>&lt;p>デスクトップに「gr-tutorial」というフォルダができているかと思います（右クリックで作成してもOKです）。&lt;code>cd&lt;/code>コマンドは移動するコマンド、&lt;code>mkdir&lt;/code>コマンドはディレクトリを作成するコマンドです。&lt;/p>
&lt;h3 id="pythontensorflow">Python＆Tensorflow環境構築&lt;/h3>
&lt;p>今回はご自身の環境に、以下の内容を用意し進めます。&lt;/p>
&lt;ul>
&lt;li>Python実行環境&lt;/li>
&lt;li>Tensorflow&lt;/li>
&lt;/ul>
&lt;p>環境構築はおそらく&lt;strong>このハンズオンで1番大変なところ&lt;/strong>です。乗り越えたらサクッと試せるようになるので頑張りましょう！&lt;/p>
&lt;p>PCの状態に合わせて場合分けしましたので、ご自身に合う部分を読んでください。&lt;/p>
&lt;h3 id="heading-12">まずは現在の環境を確認する&lt;/h3>
&lt;p>下記コマンドを試して、PythonとTensorFlowがインストールされているか確認しましょう。コマンドは&lt;code>$&lt;/code>マークの後ろの部分です。（↓の場合は&lt;code>python -V&lt;/code>と打ち込む）&lt;/p>
&lt;pre>&lt;code>$ python -V
Python X.X.X
&lt;/code>&lt;/pre>&lt;p>Pythonのバージョンが表示されればOKです。「command not found」や「実行する〜〜が見つかりません」などと表示された方は、インストールされていない（または正しくインストールできていない）のでPythonの環境構築手順を進めます。&lt;/p>
&lt;p>インストールされていなかった方は、「&lt;a href="#Python%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB">Pythonをインストール&lt;/a>」へ進んでください。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>続いて、Tensorflowモジュールがインストールされているかの確認です。&lt;code>pip list&lt;/code>と打ち込んでみましょう。（表示されるものは一例）&lt;/p>
&lt;pre>&lt;code>$ pip list
Package Version
---------------------- ---------
absl-py 0.6.1
bleach 1.5.0
html5lib 0.9999999
Markdown 3.0.1
nose 1.3.7
numpy 1.15.3
pip 18.1
protobuf 3.6.1
setuptools 39.0.1
six 1.11.0
tensorflow 1.5.0
…
&lt;/code>&lt;/pre>&lt;p>一覧に&lt;code>tensorflow&lt;/code>とあればOKです。バージョンが古い場合は、下記コマンドで更新をしておきましょう（最新は1.5系です）。&lt;/p>
&lt;ul>
&lt;li>Python2系の場合&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>$ pip install --upgrade tensorflow
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Python3系の場合&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>$ pip3 install --upgrade tensorflow
&lt;/code>&lt;/pre>&lt;p>PythonがインストールされているがTensorflowはインストールされていない場合は、「&lt;a href="#tensorflow%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB">Tensorflowをインストール&lt;/a>」へ進んでください。&lt;/p>
&lt;p>どちらもインストールされていた場合は、「&lt;a href="#MNIST%E3%81%A7%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E4%BD%9C%E6%88%90">MNISTで学習モデルを作成&lt;/a>」へ進みます。&lt;/p>
&lt;h3 id="python">Pythonをインストール&lt;/h3>
&lt;h4 id="windows-3">■Windowsの方&lt;/h4>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>&lt;a href="https://www.python.org/downloads/windows/">Pythonの公式ページ&lt;/a>へ移動し、インストールしたいPythonのバージョンをクリックします。（Tensorflowがうまく動かないので&lt;strong>Python3.7系は避けてください&lt;/strong>。3.6.xがオススメです。）&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>移動先のページ下部のリストから、「Windows x86-64 web-based installer」をダウンロードします。32bit版の場合は「Windows x86 web-based installer」を選択してください。&lt;/p>
&lt;p>ダウンロードされたパッケージを実行し、「&lt;strong>Add Python xxx to PATH&lt;/strong>」をチェックしてインストールを実行します。&lt;/p>
&lt;p>完了したら、コマンドプロンプトで&lt;code>python -V&lt;/code>を打ち、任意のバージョンが表示されるか確認します。&lt;/p>
&lt;pre>&lt;code>$ python -V
Python X.X.X
&lt;/code>&lt;/pre>&lt;p>表示されない方はコマンドプロンプトを再起動して試してみてください。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="mac-1">■Macの方&lt;/h4>
&lt;p>デフォルトでPython2系がインストールされているはずですが、何かのタイミングで消してしまった可能性があります。&lt;/p>
&lt;p>ターミナルで下記コマンドを実行し、Homebrewがインストールされているか確認します。&lt;/p>
&lt;pre>&lt;code>$ brew -v
Homebrew x.x.x
&lt;/code>&lt;/pre>&lt;p>インストールされていない場合は下記コマンドを実行します。&lt;/p>
&lt;pre>&lt;code>$ /usr/bin/ruby -e &amp;quot;$(curl -fsSLhttps://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
&lt;/code>&lt;/pre>&lt;p>続いてHomebrewでpyenvをインストールします。pyenvはPythonのバージョン管理を行うツールです。&lt;/p>
&lt;pre>&lt;code>$ brew install pyenv
&lt;/code>&lt;/pre>&lt;p>インストールされたら下記コマンドで確認します。&lt;/p>
&lt;pre>&lt;code>$ pyenv -v
pyenv x.x.x
&lt;/code>&lt;/pre>&lt;p>pyenvでPythonをインストールします。バージョンは任意のものでよいですが、Tensorflowがうまく動かないので&lt;strong>3.7系は避けてください&lt;/strong>。&lt;/p>
&lt;pre>&lt;code>$ pyenv install 3.6.7
&lt;/code>&lt;/pre>&lt;p>完了したら、選択したバージョンを設定します。&lt;/p>
&lt;pre>&lt;code>$ pyenv global 3.6.7
&lt;/code>&lt;/pre>&lt;p>ターミナルで下記コマンドを実行し、バージョンが表示されるか確認してみてください。&lt;/p>
&lt;pre>&lt;code>$ python -V
Python 3.6.7
&lt;/code>&lt;/pre>&lt;h3 id="tensorflow">TensorFlowをインストール&lt;/h3>
&lt;p>コマンドラインで下記コマンドを実行します。&lt;/p>
&lt;pre>&lt;code>$ pip install tensorflow
&lt;/code>&lt;/pre>&lt;p>だらだらと実行文が表示され、最後の行に &lt;code>Successfully installed tensorflow-X.X.X&lt;/code>などと表示されればOKです。&lt;/p>
&lt;p>&lt;code>pip list&lt;/code>というコマンドを打って、インストールされたか確認してみます。（表示されるものは一例）&lt;/p>
&lt;pre>&lt;code>$ pip list
Package Version
---------------------- ---------
absl-py 0.6.1
bleach 1.5.0
html5lib 0.9999999
Markdown 3.0.1
nose 1.3.7
numpy 1.15.3
pip 18.1
protobuf 3.6.1
setuptools 39.0.1
six 1.11.0
tensorflow 1.5.0
…
&lt;/code>&lt;/pre>&lt;p>一覧に、&lt;code>tensorflow&lt;/code>とあればOKです。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="heading-13">■実行したらエラーが出た&lt;/h4>
&lt;p>長い実行文が表示されたあと、最後の一行が下記のようなエラー文になることがあります。&lt;/p>
&lt;pre>&lt;code>Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/Library/Python/2.7/site-packages/tensorflow-1.11.0.dist-info' Consider using the --user option or check the permissions.
&lt;/code>&lt;/pre>&lt;p>下記コマンドを再度実行します。&lt;/p>
&lt;pre>&lt;code>$ sudo pip install tensorflow
&lt;/code>&lt;/pre>&lt;p>パスワードを求められるので、PCのユーザのパスワードを入力します。（入力したパスワードは表示されません）&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="heading-14">■エラーが出てインストールが実行されない①&lt;/h4>
&lt;p>&lt;code>pip install tensorflow&lt;/code>を実行すると、&lt;code>command not found&lt;/code>といったエラーが出る場合があります。以下のコマンドを実行し、pipをインストールします。&lt;/p>
&lt;pre>&lt;code>$ python -m ensurepip
&lt;/code>&lt;/pre>&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="heading-15">■エラーが出てインストールが実行されない②&lt;/h4>
&lt;p>&lt;code>pip install tensorflow&lt;/code>を実行すると、下記のようなエラーが出る場合があります。&lt;/p>
&lt;pre>&lt;code>Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow
&lt;/code>&lt;/pre>&lt;p>以下のコマンドを再度実行しましょう。&lt;/p>
&lt;ul>
&lt;li>Python2系&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>$ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.11.0-py2-none-any.wh
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Python3系&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>$ python3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.5.0-py3-none-any.whl
&lt;/code>&lt;/pre>&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="list">■インストールしたのにlistに表示されない&lt;/h4>
&lt;p>主にMacで、Python環境がPC上に複数あり、意図する場所にインストールできていない可能性があります。&lt;/p>
&lt;p>主に下記の記事を参考にしてみてください。&lt;/p>
&lt;ul>
&lt;li>参考: &lt;a href="https://qiita.com/ta_ta_ta_miya/items/e24394c6b0022405a126">pyenvでPythonがSystemバージョンから切り替わらない時の対処&lt;/a>&lt;/li>
&lt;li>参考: &lt;a href="https://qiita.com/mckyhrs/items/94a2db3506287df0420e">pythonのバージョンが切り替わらない&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="mnist">MNISTで学習モデルを作成&lt;/h3>
&lt;p>画像認識向けに、大量の画像を自分で収集し学習用に加工するのはとても大変です。&lt;/p>
&lt;p>MNIST（Mixed National Institute of Standards and Technology database）は、手書き数字画像60,000枚とテスト画像10,000枚を集めたデータセットです。&lt;/p>
&lt;p>手軽に入手でき簡単に扱えるので、AI入門のサンプルデータとしてオススメです。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="mnistpython">■MNIST用Pythonコードを作成&lt;/h4>
&lt;p>作成した作業用ディレクトリに、コマンドか右クリックなどで&lt;code>mnist_softmax_for_e-ai.py&lt;/code>というファイルを作成します。&lt;/p>
&lt;p>プログラム向けのエディタでファイルを開き、下記のプログラムを貼り付けます。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code> &amp;quot;&amp;quot;&amp;quot;A very simple MNIST classifier.
See extensive documentation at
https://www.tensorflow.org/get_started/mnist/beginners
&amp;quot;&amp;quot;&amp;quot;
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import argparse
import sys
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
FLAGS = None
def main(_):
# Import data
mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)
# Create the model
x = tf.placeholder(tf.float32, [None, 784])
#Add Renesas 2 --------- ----------
# change
# x_ = tf.placeholder(tf.float32, [None, 784])
# x = tf.reshape(x_, [-1])
# --------- ----------
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
y = tf.matmul(x, W) + b
# Define loss and optimizer
y_ = tf.placeholder(tf.float32, [None, 10])
# The raw formulation of cross-entropy,
#
# tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),
# reduction_indices=[1]))
#
# can be numerically unstable.
#
# So here we use tf.nn.softmax_cross_entropy_with_logits on the raw
# outputs of 'y', and then average across the batch.
cross_entropy = tf.reduce_mean(
tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
sess = tf.InteractiveSession()
tf.global_variables_initializer().run()
# Train
for _ in range(1000):
batch_xs, batch_ys = mnist.train.next_batch(100)
sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
# Test trained model
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(sess.run(accuracy, feed_dict={x: mnist.test.images,
y_: mnist.test.labels}))
#Add Renesas 1 --------- ----------
import os
#Save Learned AI
out_dir = &amp;quot;./tf_LearnedModel&amp;quot;
if os.path.isdir(out_dir) is False:
os.makedirs(out_dir)
saver = tf.train.Saver()
saver.save(sess, out_dir+&amp;quot;/tf_LearnedModel&amp;quot;)
# --------- ----------
if __name__ == '__main__':
parser = argparse.ArgumentParser()
parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',
help='Directory for storing input data')
FLAGS, unparsed = parser.parse_known_args()
tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
&amp;lt;/code&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>今回はがじぇるねさんの&lt;a href="http://gadget.renesas.com/ja/product/e-ai/mnist_tutorial.html#%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AE%E5%AE%9F%E8%A1%8C">チュートリアルのサンプルコード&lt;/a>をお借りしました！&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="tensorflow-1">■Tensorflowで実行&lt;/h4>
&lt;p>下記コマンドで学習モデルを作成します。&lt;/p>
&lt;pre>&lt;code>$ python mnist_softmax_for_e-ai.py
&lt;/code>&lt;/pre>&lt;p>pythonコマンドはPythonで書かれたプログラムを実行するコマンドです。ファイルの中のプログラムが実行され、学習モデルが作成されます。&lt;/p>
&lt;p>Windowsの方は&lt;code>dir&lt;/code>、Macの方は&lt;code>ls&lt;/code>というコマンドを実行し、「tf_LearnedModel」というフォルダが作成されたことを確認してください。&lt;/p>
&lt;pre>&lt;code>$ ls
mnist_softmax_for_e-ai.py
tf_LearnedModel/
&lt;/code>&lt;/pre>&lt;p>Windowsは&lt;code>dir tf_LearnedModel&lt;/code>、Macは&lt;code>ls tf_LearnedModel&lt;/code>のコマンドを実行すると、4つのファイルが入っていることがわかります。&lt;/p>
&lt;pre>&lt;code>$ ls tf_LearnedModel
checkpoint
tf_LearnedModel.data-00000-of-00001
tf_LearnedModel.index
tf_LearnedModel.meta
&lt;/code>&lt;/pre>&lt;h3 id="gr">学習モデルをGRボードで扱う&lt;/h3>
&lt;p>&lt;img src="https://i.gyazo.com/045295f6fe6ebda3cbed3d0150650c27.png" alt="Image from Gyazo">
Webコンパイラを開き、右側のリストから「e-AI Translator」をクリックします。&lt;/p>
&lt;p>&lt;img src="https://i.gyazo.com/1ae615bd6f71338dab09647185d3bcb5.png" alt="Image from Gyazo">
アップロードボタンを押し、先ほど作成された「tf_LearnedModel」を選択します。&lt;/p>
&lt;p>&lt;img src="https://i.gyazo.com/2d54b87b9a6c9852f31c1afb14132614.png" alt="Image from Gyazo">
その他はデフォルト選択のまま、「トランスレート」をクリックします。&lt;/p>
&lt;p>&lt;img src="https://i.gyazo.com/27fe23312950242e2eee4ff2e6e7ee79.png" alt="Image from Gyazo">
表示されたプログラムを全て選択してコピーします。&lt;/p>
&lt;h2 id="heading-16">完成コード&lt;/h2>
&lt;p>上記で生成されたプログラムに、displayAppに表示させるためのコードを加えたプログラムです。USBケーブルは真ん中に接続し、GR-LYCHEEに書き込みましょう。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code> #ifdef __cplusplus
extern &amp;quot;C&amp;quot; {
#endif
#include &amp;quot;eAI_translated/Typedef.h&amp;quot;
#include &amp;quot;eAI_translated/input_image_0.h&amp;quot;
#include &amp;quot;eAI_translated/layer_graph.h&amp;quot;
TPrecision* dnn_compute(TPrecision* input_img);
#ifdef __cplusplus
}
#endif
// To monitor realtime on PC, you need DisplayApp on following site.
// Connect USB0(not for mbed interface) to your PC
// os.mbed.com/.../
using namespace cv;
#define IMAGE_HW 320
#define IMAGE_VW 240
#define INPUT_HEIGHT 28
#define INPUT_WIDTH 28
Camera camera(IMAGE_HW, IMAGE_VW);
DisplayApp display_app;
void paste(cv::Mat dst, cv::Mat src, int x, int y, int width, int height) {
cv::Mat resized_img;
cv::resize(src, resized_img, cv::Size(width, height));
if (x &amp;gt;= dst.cols || y &amp;gt;= dst.rows) return;
int w = (x &amp;gt;= 0) ? std::min(dst.cols - x, resized_img.cols) : std::min(std::max(resized_img.cols + x, 0), dst.cols);
int h = (y &amp;gt;= 0) ? std::min(dst.rows - y, resized_img.rows) : std::min(std::max(resized_img.rows + y, 0), dst.rows);
int u = (x &amp;gt;= 0) ? 0 : std::min(-x, resized_img.cols - 1);
int v = (y &amp;gt;= 0) ? 0 : std::min(-y, resized_img.rows - 1);
int px = std::max(x, 0);
int py = std::max(y, 0);
cv::Mat roi_dst = dst(cv::Rect(px, py, w, h));
cv::Mat roi_resized = resized_img(cv::Rect(u, v, w, h));
roi_resized.copyTo(roi_dst);
}
int max_array(TPrecision* array, int length){
int i;
float max = array[0];
int index = 0;
for(i = 0; i &amp;lt; length; i++){
if(array[i] &amp;gt; max){
max = array[i];
index = i;
}
}
return index;
}
void setup() {
Serial.begin(9600);
camera.begin();
}
void loop() {
Scalar red(0, 0, 255), green(0, 255, 0), blue(255, 0, 0);
Scalar yellow = red + green;
Scalar white = Scalar::all(255);
Scalar black = Scalar::all(0);
Scalar pink = Scalar(154, 51, 255);
Mat img_raw(IMAGE_VW, IMAGE_HW, CV_8UC2, camera.getImageAdr());
Mat pic, gray;
cvtColor(img_raw, pic, COLOR_YUV2BGR_YUYV); //covert YUV to RGB
cvtColor(img_raw, gray, COLOR_YUV2GRAY_YUYV); //covert from YUV to GRAY
Mat roi(gray, Rect(80, 0, 240, 240));
threshold(roi, roi, 90, 255, THRESH_BINARY);
resize(roi, roi, Size(INPUT_WIDTH, INPUT_HEIGHT));
for(int i = 0; i &amp;lt; 784; i++){
data_in[i] = 1 - (float)roi.data[i] / 255;
}
TPrecision *prediction;
TPrecision *input_img;
TsInt i;
input_img = data_in;
prediction = (TPrecision*) (intptr_t) dnn_compute( input_img);
// Drawing
rectangle(pic, Rect(0, 0, 80, 240), white, FILLED);
rectangle(pic, Rect(80, 0, 240, 240), red, 2);
Mat roi2;
cvtColor(roi, roi2, COLOR_GRAY2BGR);
paste(pic, roi2, 5, 5, roi2.rows, roi2.cols);
rectangle(pic, Rect(4, 4, 30, 30), red, 1);
int max_index = max_array(prediction, 10);
for(i = 0;i &amp;lt; 10;i++){
Serial.print(i); Serial.print(&amp;quot;:&amp;quot;);
Serial.println(prediction[i]);
stringstream ss;
ss &amp;lt;&amp;lt; i;
if(max_index == i){
putText(pic, ss.str(), Point(0, 20 * i + 50), FONT_HERSHEY_SCRIPT_SIMPLEX, 0.5, pink, 1);
rectangle(pic, Rect(20, 20 * i + 40, prediction[i] * 80, 10), pink, FILLED);
} else {
putText(pic, ss.str(), Point(0, 20 * i + 50), FONT_HERSHEY_SCRIPT_SIMPLEX, 0.5, black, 1);
rectangle(pic, Rect(20, 20 * i + 40, prediction[i] * 80, 10), blue, FILLED);
}
}
size_t jpegSize = camera.createJpeg(320, 240, pic.data,
Camera::FORMAT_RGB888);
display_app.SendJpeg(camera.getJpegAdr(), jpegSize);
delay(10);
}
&amp;lt;/code&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>これまでの手順と同様、書き込んでみましょう。&lt;/p>
&lt;h2 id="heading-17">手書き数字の認識を試してみる&lt;/h2>
&lt;p>USBケーブルを外側につけかえ、試してみます。&lt;/p>
&lt;h3 id="displayapp-1">displayAppで表示&lt;/h3>
&lt;p>紙に書く文字は、マッキーペンなどで太くハッキリと書いてみてください。&lt;/p>
&lt;p>カメラに数字を映すと……&lt;/p>
&lt;p>&lt;img src="https://dotstud.io/img/blog/233/result.gif" alt="demo">&lt;/p>
&lt;p>数字を推論してくれます。お疲れ様でした！&lt;/p>
&lt;h3 id="heading-18">シリアルモニタで表示&lt;/h3>
&lt;p>GR-LYCHEEで実行されている内容を、シリアル通信を介してPCで確認してみます。&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="mac-2">■Macの方&lt;/h4>
&lt;p>下記コマンドを実行し、USB接続されている場所を調べます。&lt;/p>
&lt;pre>&lt;code>$ ls /dev/tty.usb*
/dev/tty.usbmodem~~~
&lt;/code>&lt;/pre>&lt;p>接続されている場所をコピーし、下記コマンドで接続します。&lt;/p>
&lt;pre>&lt;code>$ screen /dev/tty.usbmodem~~~~ 9600
&lt;/code>&lt;/pre>&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;h4 id="windows-4">■Windowsの方&lt;/h4>
&lt;p>「TeraTerm」というシリアル通信対応のソフトをダウンロード＆インストールします。「Arduino IDE」がインストールされている方は、そちらでも確認できます。&lt;/p>
&lt;p>下記リンクを参考に、TeraTermを起動しシリアル接続します。&lt;/p>
&lt;p>参考: &lt;a href="https://www.j-oosk.com/teraterm/serial/346/">Tera Termでシリアル接続を行う手順&lt;/a>&lt;/p>
&lt;h2 id="heading-19">参考情報&lt;/h2>
&lt;p>がじぇるねさんのページでは、その他のGR-LYCHEEチュートリアルも紹介されています。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://gadget.renesas.com/ja/product/lychee_sp/4.html">Webカメラにしてみよう!&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://gadget.renesas.com/ja/product/lychee_sp/5.html">Bluetoothでスマホとつなげよう!&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://gadget.renesas.com/ja/product/lychee_sp/8.html">OpenCTの応用 輪郭検出、HSV色空間&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>ぜひ試してみてください！&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted --></description></item></channel></rss>